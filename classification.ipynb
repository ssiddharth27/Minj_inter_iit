{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "\n",
      "[notice] A new release of pip available: 22.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flaml in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (1.0.14)\n",
      "Requirement already satisfied: xgboost>=0.90 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from flaml) (1.7.2)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from flaml) (3.2.1)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from flaml) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from flaml) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from flaml) (1.7.3)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from flaml) (1.4.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from lightgbm>=2.3.1->flaml) (0.37.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.1.4->flaml) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=0.24->flaml) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn>=0.24->flaml) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml) (1.16.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn\n",
    "%pip install flaml\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "    \"poco f2\",\n",
    "    \"iphone\",\n",
    "    \"galaxy\",\n",
    "    \"uplift\",\n",
    "    \"iphone (apple)\",\n",
    "    \"realme\",\n",
    "    \"xgody\",\n",
    "    \"xiamoi\",\n",
    "    \"huawei\",\n",
    "    \"mediatek\",\n",
    "    \"asus\",\n",
    "    \"lg\",\n",
    "    \"zte\",\n",
    "    \"tecno\",\n",
    "    \"motorola\",\n",
    "    \"poco m2\",\n",
    "    \"vivo\",\n",
    "    \"moto\",\n",
    "    \"itel\",\n",
    "    \"apple\",\n",
    "    \"acer\",\n",
    "    \"dimensity\",\n",
    "    \"poco\",\n",
    "    \"redmi\",\n",
    "    \"hmd\",\n",
    "    \"samsung\",\n",
    "    \"hmd global (nokia)\",\n",
    "    \"micromax\",\n",
    "    \"xiaomi\",\n",
    "    \"ismart\",\n",
    "    \"galaxy (samsung)\",\n",
    "    \"one plus\",\n",
    "    \"black shark (xiaomi )\",\n",
    "    \"tecno\",\n",
    "    \"lava\",\n",
    "    \"qualcomm\",\n",
    "    \"koomus\",\n",
    "    \"exynos\",\n",
    "    \"iqoo\",\n",
    "    \"i kall\",\n",
    "    \"sony\",\n",
    "    \"iphone(apple)\",\n",
    "    \"bsnl\",\n",
    "    \"jio\",\n",
    "    \"galaxynote20ultra\",\n",
    "    \"realmex7pro\",\n",
    "    \"google\",\n",
    "    \"coolpad\",\n",
    "    \"aspera\",\n",
    "    \"oppo\",\n",
    "    \"honor\",\n",
    "    \"oneplus\",\n",
    "    \"nokia\",\n",
    "    \"pixel\",\n",
    "    \"infinix\",\n",
    "    \"potronics\",\n",
    "    \"mi\",\n",
    "    \"axon\",\n",
    "    \"lantronix\",\n",
    "    \"pocox3\",\n",
    "    \"blackberry\",\n",
    "    \"पोको एफ 2\",\n",
    "    \"आइफोन\",\n",
    "    \"गैलेक्सी\",\n",
    "    \"अपलिफ्ट\",\n",
    "    \"आइफोन (एप्पल)\",\n",
    "    \"रियलमी\",\n",
    "    \"एक्सगोडी\",\n",
    "    \"शाओमी\",\n",
    "    \"हुवाई\",\n",
    "    \"मीडियाटेक\",\n",
    "    \"आसूस\",\n",
    "    \"एलजी\",\n",
    "    \"जेडटीई\",\n",
    "    \"टेक्नो\",\n",
    "    \"मोटोरोला\",\n",
    "    \"पोको एम 2\",\n",
    "    \"वीवो\",\n",
    "    \"मोटो\",\n",
    "    \"मी\",\n",
    "    \"आईटेल\",\n",
    "    \"एप्पल\",\n",
    "    \"एसर\",\n",
    "    \"पोको\",\n",
    "    \"रेडमी\",\n",
    "    \"एचएमडी\",\n",
    "    \"सैमसंग\",\n",
    "    \"एचएमडी ग्लोबल (नोकिया)\",\n",
    "    \"माइक्रोमैक्स\",\n",
    "    \"आइस्‍मार्ट\",\n",
    "    \"गैलेक्सी (सैमसंग)\",\n",
    "    \"वन प्लस\",\n",
    "    \"ब्लैक शार्क (शाओमी)\",\n",
    "    \"टेकोनो\",\n",
    "    \"लावा\",\n",
    "    \"क्वालकॉम\",\n",
    "    \"कुओमस\",\n",
    "    \"एक्सिनोस\",\n",
    "    \"आई कॉल\",\n",
    "    \"सोनी\",\n",
    "    \"बीएसएनएल\",\n",
    "    \"जियो\",\n",
    "    \"गूगल\",\n",
    "    \"कूलपैड\",\n",
    "    \"ओप्पो\",\n",
    "    \"हॉनर\",\n",
    "    \"वनप्लस\",\n",
    "    \"नोकिया\",\n",
    "    \"पिक्सेल\",\n",
    "    \"पोट्रोनिक्स\",\n",
    "    \"मी\",\n",
    "    \"एक्सोन\",\n",
    "    \"लैनट्रोनिक्स\"\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/Tech-Meet-Solutions/Bridgei2i_NLP_9th_InterIIT_Tech_Meet/main/data/dev_data_article.csv\")\n",
    "dft = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/Tech-Meet-Solutions/Bridgei2i_NLP_9th_InterIIT_Tech_Meet/main/data/tweet_concatenated.csv\", header=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.columns = ['a', 'b', 'c', 'd', 'e']\n",
    "dft3 = dft[dft['c'].str.lower().isin(companies)]['b']\n",
    "dft4 = dft[dft['d'].str.lower().isin(companies)]['c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Mobile_Tech_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Samsung is now making another addition into i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QT @AwamiWeb: Want my hands on #GalaxyS21 🥺 ; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QT @MadhavSheth1: We are the pioneers of 64MP ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QT @AwamiWeb: The bestest in the smartphone in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Samsung #GalaxyS21 Ultra 5G is the most pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Mobile_Tech_Flag\n",
       "0  #Samsung is now making another addition into i...                 1\n",
       "1  QT @AwamiWeb: Want my hands on #GalaxyS21 🥺 ; ...                 1\n",
       "2  QT @MadhavSheth1: We are the pioneers of 64MP ...                 1\n",
       "3  QT @AwamiWeb: The bestest in the smartphone in...                 1\n",
       "4  The Samsung #GalaxyS21 Ultra 5G is the most pr...                 1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.DataFrame()\n",
    "df_['Text'] = list(dft3) + list(dft4)\n",
    "df_['Mobile_Tech_Flag'] = 1\n",
    "df_.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3025\n",
       "1.0    1301\n",
       "Name: Mobile_Tech_Flag, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dfa[['Text', 'Mobile_Tech_Flag']],\n",
    "               df_[['Text', 'Mobile_Tech_Flag']]])\n",
    "df['Mobile_Tech_Flag'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hindi_stop.txt',  encoding=\"utf8\") as f:\n",
    "    hindi_stop = list(f)\n",
    "hindi_stop = [i.strip() for i in hindi_stop]\n",
    "\n",
    "with open('hinglish_stop.txt',  encoding=\"utf8\") as f:\n",
    "    hinglish_stop = list(f)\n",
    "hinglish_stop = [i.strip() for i in hinglish_stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    number_pattern = r'\\d+'\n",
    "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
    "    return without_number\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    removed = []\n",
    "    stop_words = list(stopwords.words(\"english\")) + hindi_stop + hinglish_stop\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in stop_words:\n",
    "            removed.append(tokens[i])\n",
    "    return \" \".join(removed)\n",
    "\n",
    "\n",
    "def remove_n(text):\n",
    "    single_char_pattern = r'\\n'\n",
    "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
    "    return without_sc\n",
    "\n",
    "\n",
    "def remove_extra_white_spaces(text):\n",
    "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
    "    return without_sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df['length'] = df['Text'].apply(lambda x: len(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: convert_to_lower(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_n(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_extra_white_spaces(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_punctuation(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_stopwords(x))\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_numbers(x))\n",
    "df['length_after_cleaning'] = df['Text'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Mobile_Tech_Flag</th>\n",
       "      <th>length</th>\n",
       "      <th>length_after_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digitisation key buzzwords postcovid world dig...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>828</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increase tolerance limit   cent   cent real es...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4276</td>\n",
       "      <td>2721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Mobile_Tech_Flag  \\\n",
       "0  digitisation key buzzwords postcovid world dig...               0.0   \n",
       "1  increase tolerance limit   cent   cent real es...               0.0   \n",
       "\n",
       "   length  length_after_cleaning  \n",
       "0     828                    603  \n",
       "1    4276                   2721  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Mobile_Tech_Flag</th>\n",
       "      <th>length</th>\n",
       "      <th>length_after_cleaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>भारत में लॉन्च xiaomi mi  i है   सस्ता  g फोन ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>qt anjalisinghin phone galat choose kr haisorr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>449</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Mobile_Tech_Flag  \\\n",
       "325  भारत में लॉन्च xiaomi mi  i है   सस्ता  g फोन ...               1.0   \n",
       "326  qt anjalisinghin phone galat choose kr haisorr...               1.0   \n",
       "\n",
       "     length  length_after_cleaning  \n",
       "325     199                    150  \n",
       "326     449                    309  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4325, 48525)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(df['Text'])\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf = X.toarray()\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(\n",
    "    X_tf, df['Mobile_Tech_Flag'].values, test_size=0.3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-21 16:28:13] {2599} INFO - task = classification\n",
      "[flaml.automl: 12-21 16:28:13] {2601} INFO - Data split method: stratified\n",
      "[flaml.automl: 12-21 16:28:13] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 12-21 16:28:21] {2726} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 12-21 16:28:21] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 12-21 16:28:21] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 12-21 16:28:22] {3296} INFO - Estimated sufficient time budget=12018s. Estimated necessary time budget=277s.\n",
      "[flaml.automl: 12-21 16:28:22] {3343} INFO -  at 9.7s,\testimator lgbm's best error=0.0961,\tbest estimator lgbm's best error=0.0961\n",
      "[flaml.automl: 12-21 16:28:22] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 12-21 16:28:24] {3343} INFO -  at 10.8s,\testimator lgbm's best error=0.0624,\tbest estimator lgbm's best error=0.0624\n",
      "[flaml.automl: 12-21 16:28:24] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 12-21 16:28:25] {3343} INFO -  at 12.2s,\testimator lgbm's best error=0.0624,\tbest estimator lgbm's best error=0.0624\n",
      "[flaml.automl: 12-21 16:28:25] {3166} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 12-21 16:28:26] {3343} INFO -  at 13.3s,\testimator lgbm's best error=0.0366,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:28:26] {3166} INFO - iteration 4, current learner xgboost\n",
      "c:\\Users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl: 12-21 16:28:44] {3343} INFO -  at 31.8s,\testimator xgboost's best error=0.0961,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:28:44] {3166} INFO - iteration 5, current learner extra_tree\n",
      "[flaml.automl: 12-21 16:28:45] {3343} INFO -  at 32.4s,\testimator extra_tree's best error=0.3179,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:28:45] {3166} INFO - iteration 6, current learner xgboost\n",
      "c:\\Users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl: 12-21 16:29:03] {3343} INFO -  at 50.7s,\testimator xgboost's best error=0.0731,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:03] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 12-21 16:29:04] {3343} INFO -  at 51.7s,\testimator lgbm's best error=0.0366,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:04] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 12-21 16:29:06] {3343} INFO -  at 52.9s,\testimator lgbm's best error=0.0366,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:06] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 12-21 16:29:07] {3343} INFO -  at 53.9s,\testimator lgbm's best error=0.0366,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:07] {3166} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl: 12-21 16:29:07] {3343} INFO -  at 54.6s,\testimator extra_tree's best error=0.1869,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:07] {3166} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl: 12-21 16:29:08] {3343} INFO -  at 55.2s,\testimator extra_tree's best error=0.1869,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:08] {3166} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 12-21 16:29:08] {3343} INFO -  at 55.8s,\testimator rf's best error=0.2183,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:08] {3166} INFO - iteration 13, current learner rf\n",
      "[flaml.automl: 12-21 16:29:09] {3343} INFO -  at 56.4s,\testimator rf's best error=0.1246,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:09] {3166} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 12-21 16:29:10] {3343} INFO -  at 57.0s,\testimator rf's best error=0.1246,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:10] {3166} INFO - iteration 15, current learner xgboost\n",
      "c:\\Users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl: 12-21 16:29:27] {3343} INFO -  at 74.6s,\testimator xgboost's best error=0.0731,\tbest estimator lgbm's best error=0.0366\n",
      "[flaml.automl: 12-21 16:29:27] {3166} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 12-21 16:29:28] {3343} INFO -  at 75.7s,\testimator lgbm's best error=0.0364,\tbest estimator lgbm's best error=0.0364\n",
      "[flaml.automl: 12-21 16:29:28] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 12-21 16:29:30] {3343} INFO -  at 76.9s,\testimator extra_tree's best error=0.1344,\tbest estimator lgbm's best error=0.0364\n",
      "[flaml.automl: 12-21 16:29:30] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 12-21 16:29:31] {3343} INFO -  at 78.1s,\testimator lgbm's best error=0.0230,\tbest estimator lgbm's best error=0.0230\n",
      "[flaml.automl: 12-21 16:29:31] {3166} INFO - iteration 19, current learner rf\n",
      "[flaml.automl: 12-21 16:29:32] {3343} INFO -  at 79.1s,\testimator rf's best error=0.1066,\tbest estimator lgbm's best error=0.0230\n",
      "[flaml.automl: 12-21 16:29:32] {3166} INFO - iteration 20, current learner xgb_limitdepth\n",
      "c:\\Users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl: 12-21 16:29:35] {3343} INFO -  at 82.8s,\testimator xgb_limitdepth's best error=0.0413,\tbest estimator lgbm's best error=0.0230\n",
      "[flaml.automl: 12-21 16:29:37] {3602} INFO - retrain lgbm for 1.4s\n",
      "[flaml.automl: 12-21 16:29:37] {3609} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=25, n_estimators=11, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339125,\n",
      "               verbose=-1)\n",
      "[flaml.automl: 12-21 16:29:37] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 12-21 16:29:37] {2902} INFO - Time taken to find the best model: 78.09013414382935\n",
      "[flaml.automl: 12-21 16:29:37] {2913} WARNING - Time taken to find the best model is 98% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(colsample_bytree=0.7370133750309855,\n",
      "               learning_rate=0.10131160192564638, max_bin=1023,\n",
      "               min_child_samples=25, n_estimators=11, num_leaves=4,\n",
      "               reg_alpha=0.002668211515123386, reg_lambda=0.36111742401339125,\n",
      "               verbose=-1)\n",
      "0.8952234206471494\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(X_train_tf, y_train_tf, task=\"classification\", time_budget=80)\n",
    "pred = automl.predict(X_test_tf)\n",
    "print(automl.model.estimator)\n",
    "print(accuracy_score(y_test_tf, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214175654853621\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train_tf, y_train_tf)\n",
    "nb_pred = nb.predict(X_test_tf)\n",
    "print(accuracy_score(y_test_tf, nb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614791987673343\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_tf, y_train_tf)\n",
    "svc_pred = svc.predict(X_test_tf)\n",
    "print(accuracy_score(y_test_tf, svc_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9468412942989214\n"
     ]
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(X_train_tf, y_train_tf)\n",
    "lr_pred = lr.predict(X_test_tf)\n",
    "print(accuracy_score(y_test_tf, lr_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling imbalance using smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 2119, 0.0: 2119})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy=1)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_tf, y_train_tf)\n",
    "Counter(y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 12-21 16:42:22] {2599} INFO - task = classification\n",
      "[flaml.automl: 12-21 16:42:22] {2601} INFO - Data split method: stratified\n",
      "[flaml.automl: 12-21 16:42:22] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 12-21 16:42:25] {2726} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 12-21 16:42:25] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 12-21 16:42:25] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 12-21 16:42:27] {3296} INFO - Estimated sufficient time budget=18685s. Estimated necessary time budget=431s.\n",
      "[flaml.automl: 12-21 16:42:27] {3343} INFO -  at 5.0s,\testimator lgbm's best error=0.0473,\tbest estimator lgbm's best error=0.0473\n",
      "[flaml.automl: 12-21 16:42:27] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 12-21 16:42:29] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.0418,\tbest estimator lgbm's best error=0.0418\n",
      "[flaml.automl: 12-21 16:42:29] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 12-21 16:42:30] {3343} INFO -  at 8.2s,\testimator lgbm's best error=0.0418,\tbest estimator lgbm's best error=0.0418\n",
      "[flaml.automl: 12-21 16:42:30] {3166} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 12-21 16:42:32] {3343} INFO -  at 9.8s,\testimator lgbm's best error=0.0418,\tbest estimator lgbm's best error=0.0418\n",
      "[flaml.automl: 12-21 16:42:32] {3166} INFO - iteration 4, current learner xgboost\n",
      "c:\\Users\\swara\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "automl2 = AutoML()\n",
    "automl2.fit(X_train_smote, y_train_smote,\n",
    "            task=\"classification\", time_budget=80)\n",
    "\n",
    "pred = automl2.predict(X_test_tf)\n",
    "print(automl2.model.estimator)\n",
    "print(accuracy_score(y_test_tf, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9283513097072419\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train_smote, y_train_smote)\n",
    "nb_pred = nb.predict(X_test_tf)\n",
    "print(accuracy_score(y_test_tf, nb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9614791987673343\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_smote, y_train_smote)\n",
    "svc_pred = svc.predict(X_test_tf)\n",
    "print(accuracy_score(y_test_tf, svc_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9622496147919877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LR()\n",
    "lr.fit(X_train_smote, y_train_smote)\n",
    "lr_pred = lr.predict(X_test_tf)\n",
    "print(accuracy_score(y_test_tf, lr_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed4ead3269993e1b368884907ac167fd7ad33edd0f56d61f9faca73d265f0a84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
